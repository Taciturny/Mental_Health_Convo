{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "084a05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/run/cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a405690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import json\n",
    "from typing import List\n",
    "# import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e593ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hea.parquet', 'Mental_Health_FAQ.csv', 'preprocessed_data.parquet']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('Mental_Hea/data/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "362794cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6747</th>\n",
       "      <td>8c908f3e-6ac5-4538-9777-0b8fa31ee8ab</td>\n",
       "      <td>i'm having trouble sleeping, what should i do?</td>\n",
       "      <td>let's explore what might be causing your insomnia. are you experiencing any stress or anxiety? we can work on developing healthy sleep habits and relaxation techniques to help you sleep better.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>9d8bd2ff-24c2-4752-9633-52dfeaa3d05e</td>\n",
       "      <td>i'm having trouble with my body image.</td>\n",
       "      <td>body image issues can be difficult to deal with, but it's important to recognize that everyone has their own unique beauty. let's work on developing a more positive self-image and finding ways to appreciate your body for all it does for you.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  \\\n",
       "6747  8c908f3e-6ac5-4538-9777-0b8fa31ee8ab   \n",
       "1373  9d8bd2ff-24c2-4752-9633-52dfeaa3d05e   \n",
       "\n",
       "                                            question  \\\n",
       "6747  i'm having trouble sleeping, what should i do?   \n",
       "1373          i'm having trouble with my body image.   \n",
       "\n",
       "                                                                                                                                                                                                                                                 answer  \n",
       "6747                                                  let's explore what might be causing your insomnia. are you experiencing any stress or anxiety? we can work on developing healthy sleep habits and relaxation techniques to help you sleep better.  \n",
       "1373  body image issues can be difficult to deal with, but it's important to recognize that everyone has their own unique beauty. let's work on developing a more positive self-image and finding ways to appreciate your body for all it does for you.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_parquet('Mental_Hea/data/preprocessed_data.parquet')\n",
    "\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82f42a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2810d83ab84e7e9ca54e7cdce8cf35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403b82887a6a4f69ad4a724ecc81c397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2553a8ff4db438da1581e5bd221a133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe5ee59ff4042b2ad8756be1497b3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8032cef826ec4b06a4e4cf236d41cfa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0a8e860a5d4a3ab1abc5e1c9e4453c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd7e87b9d7846dba79a9146e60a5f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n",
      "Tokenizer: LlamaTokenizerFast(name_or_path='meta-llama/Llama-2-7b-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "from typing import Tuple\n",
    "import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "class ModelSingleton:\n",
    "    _instance = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_instance() -> Tuple[AutoModelForCausalLM, AutoTokenizer]:\n",
    "        if ModelSingleton._instance is None:\n",
    "            ModelSingleton()\n",
    "        return ModelSingleton._instance.model, ModelSingleton._instance.tokenizer\n",
    "    \n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(ModelSingleton, cls).__new__(cls)\n",
    "            cls._instance._initialize_model_and_tokenizer()\n",
    "        return cls._instance\n",
    "    \n",
    "    def _initialize_model_and_tokenizer(self):\n",
    "        model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "        \n",
    "        # Retrieve the Hugging Face token from environment variables\n",
    "        token = os.getenv(\"HUGGINGFACE_HUB_TOKEN\")\n",
    "        if token is None:\n",
    "            print(\"Warning: HUGGINGFACE_HUB_TOKEN is not set.\")\n",
    "        \n",
    "        # Configure quantization\n",
    "        quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "        # Load the model and tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=token)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name, quantization_config=quantization_config, torch_dtype=torch.float16, device_map=\"auto\", use_auth_token=token\n",
    "        )\n",
    "\n",
    "# Usage\n",
    "model, tokenizer = ModelSingleton.get_instance()\n",
    "\n",
    "# Verify the model and tokenizer\n",
    "print(f\"Model: {model}\")\n",
    "print(f\"Tokenizer: {tokenizer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36e4fb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                                                                                                                                                                                                           2246f22c-9316-4de9-9b90-7fe4f9b80792\n",
       "question                                                                                                                                                                                                                                  i'm feeling really anxious lately and i don't know why.\n",
       "answer      it's common to feel anxious at times, and there can be many reasons for it. have there been any recent changes or stressors in your life that may be contributing to your anxiety? let's work together to identify any triggers and develop coping strategies to manage your anxiety.\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_record = df.iloc[0]  # Adjust the index to select a different record if needed\n",
    "example_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c46f6301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4026</th>\n",
       "      <td>9cb38caa-74fc-4e4f-8caa-36d7e5b8c8f3</td>\n",
       "      <td>i have low self-esteem and feel like i'm not good enough. what can i do to improve my self-confidence?</td>\n",
       "      <td>it's important to challenge negative self-talk and practice self-care activities like exercise, spending time with loved ones, and engaging in hobbies. additionally, seeking help from a therapist or mental health professional can provide support and guidance.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  \\\n",
       "4026  9cb38caa-74fc-4e4f-8caa-36d7e5b8c8f3   \n",
       "\n",
       "                                                                                                    question  \\\n",
       "4026  i have low self-esteem and feel like i'm not good enough. what can i do to improve my self-confidence?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                   answer  \n",
       "4026  it's important to challenge negative self-talk and practice self-care activities like exercise, spending time with loved ones, and engaging in hobbies. additionally, seeking help from a therapist or mental health professional can provide support and guidance.  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fadbd337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What specific actions can you take to challenge your negative self-talk?\n",
      "Question 2: How can you practice self-care on a regular basis?\n",
      "Question 3: How can you seek help from a therapist or mental health professional?\n",
      "Question 4: What are some other strategies that you can use to improve your self-confidence?\n",
      "Question 5: How can you practice self-compassion and accept yourself as you are?\n"
     ]
    }
   ],
   "source": [
    "def generate_questions(context, answer, model, tokenizer):\n",
    "    # Define the prompt template\n",
    "    prompt_template = (\n",
    "        \"Given the following context and answer, generate 5 insightful questions that can be used for evaluating the ground truth:\\n\\n\"\n",
    "        \"Context: {context}\\n\"\n",
    "        \"Answer: {answer}\\n\\n\"\n",
    "        \"Questions:\\n\"\n",
    "    )\n",
    "\n",
    "    # Format the prompt with the provided context and answer\n",
    "    prompt = prompt_template.format(context=context, answer=answer)\n",
    "    \n",
    "    # Tokenize the prompt and generate text\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    # Move inputs to the same device as the model\n",
    "    device = model.device\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    \n",
    "    # Generate text using the model\n",
    "    outputs = model.generate(input_ids, max_length=512, num_return_sequences=1, do_sample=True)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract questions from the generated text\n",
    "    # Split generated text into lines\n",
    "    lines = generated_text.split('\\n')\n",
    "    \n",
    "    # Collect questions starting with numbers followed by a period\n",
    "    questions = []\n",
    "    for line in lines:\n",
    "        if line.strip().startswith(f\"{len(questions) + 1}.\"):\n",
    "            question = line.strip().split('.', 1)[-1].strip()\n",
    "            questions.append(question)\n",
    "        if len(questions) >= 5:\n",
    "            break\n",
    "    \n",
    "    return questions\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = ModelSingleton.get_instance()\n",
    "    \n",
    "    # Sample context and answer\n",
    "    context = \"i have low self-esteem and feel like i'm not good enough. what can i do to improve my self-confidence?\"\n",
    "    answer = \"it's important to challenge negative self-talk and practice self-care activities like exercise, spending time with loved ones, and engaging in hobbies. additionally, seeking help from a therapist or mental health professional can provide support and guidance\"\n",
    "    \n",
    "    questions = generate_questions(context, answer, model, tokenizer)\n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"Question {i}: {question.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75d49de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 565, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 761, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 746, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 677, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 523, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 639, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 897, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 1308, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 533, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 573, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 963, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 678, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 577, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 622, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 1002, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def generate_questions_for_sample(df, model, tokenizer, n=500,  random_state=None):\n",
    "    questions_data = []\n",
    "\n",
    "    # Limit the DataFrame to the first n records\n",
    "    df_subset = df.sample(n=n, random_state=random_state)\n",
    "    \n",
    "    for _, row in df_subset.iterrows():\n",
    "        record_id = row['id']\n",
    "        context = row['question']\n",
    "        answer = row['answer']\n",
    "        \n",
    "        # Generate questions\n",
    "        questions = generate_questions(context, answer, model, tokenizer)\n",
    "        \n",
    "        # Append questions with their IDs\n",
    "        for question in questions:\n",
    "            questions_data.append({'id': record_id, 'question': question})\n",
    "    \n",
    "    return questions_data\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = ModelSingleton.get_instance()\n",
    "\n",
    "    questions_data = generate_questions_for_sample(df, model, tokenizer)\n",
    "    \n",
    "    # Create a DataFrame from the questions_data and save it to a parquet file\n",
    "    questions_df = pd.DataFrame(questions_data)\n",
    "    questions_df.to_parquet('generated_questions.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a21de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
