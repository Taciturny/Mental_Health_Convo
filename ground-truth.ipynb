{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3fe528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/run/cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b12361f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.44.0.dev0\n",
      "Uninstalling transformers-4.44.0.dev0:\n",
      "  Successfully uninstalled transformers-4.44.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d298fa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-l2q_paz0\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-l2q_paz0\n",
      "  Resolved https://github.com/huggingface/transformers to commit c85510f958e6955d88ea1bafb4f320074bfbd0c1\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers==4.44.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers==4.44.0.dev0) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers==4.44.0.dev0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers==4.44.0.dev0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers==4.44.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers==4.44.0.dev0) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers==4.44.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers==4.44.0.dev0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers==4.44.0.dev0) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers==4.44.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.0.dev0) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.0.dev0) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->transformers==4.44.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->transformers==4.44.0.dev0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->transformers==4.44.0.dev0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->transformers==4.44.0.dev0) (2023.11.17)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.44.0.dev0-py3-none-any.whl size=9412925 sha256=a0ac28252cc686989a487895c4b6ec9037db93d06af905484efa150df2c286d3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-lborwvsf/wheels/14/a0/7b/8f6b25ba4110aa215fcb8d6aedd6cd4f9b9b6619190999ac2b\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.44.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb9fd391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (2.14.7)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from datasets) (2.2.0)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: xxhash in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from datasets) (0.24.1)\n",
      "Requirement already satisfied: packaging in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, requests, fsspec, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.6.1\n",
      "    Uninstalling fsspec-2024.6.1:\n",
      "      Successfully uninstalled fsspec-2024.6.1\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.7\n",
      "    Uninstalling datasets-2.14.7:\n",
      "      Successfully uninstalled datasets-2.14.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "saturnfs 0.0.1 requires fsspec==2023.1.0, but you have fsspec 2024.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.20.0 fsspec-2024.5.0 requests-2.32.3 tqdm-4.66.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b97b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d93e3d41a8b4efc9791fd9f5584b577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d0eccaefce4654b2322809b0399c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.79M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709ef5cae06941669bc814ec1a1b9835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('Amod/mental_health_counseling_conversations', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eac9cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2cbcae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc6940ec730>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b57c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87358b261944f6faadf9da524c29ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c2d3f0c7a44269bb73ba64690ec97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe3f1a831e041b5abad50024c7c3a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc3a3660a4e4626ab51db424cbfe596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10be8cb5e8e4fae9e134bbd109f8b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ed8074ac9e453db6ed2c9cad87b50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4473de98148e40ba95610f244faefed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b1b56236f444ef9a93bfdf93adadf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3fd01abbd940d3b18f384d1685d6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d097f7e5d4e4899a1071c0b8cd74ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b344781c624312a153ea55070eeb84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64aaf6759c5640249e8dab00bca2472e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabe62b86e5e431086e2d61288cb50cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f4af4b325b4748800c30373bbc1dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-128k-instruct\", \n",
    "    device_map=\"cuda\", \n",
    "    torch_dtype=\"auto\", \n",
    "    trust_remote_code=True, \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a47441ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "overlay         100G   36G   65G  36% /\r\n",
      "tmpfs            64M     0   64M   0% /dev\r\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/fs/cgroup\r\n",
      "/dev/nvme0n1p1  100G   36G   65G  36% /run\r\n",
      "tmpfs            14G  4.0K   14G   1% /dev/shm\r\n",
      "/dev/nvme2n1    2.0G  1.9G     0 100% /home/jovyan\r\n",
      "tmpfs            14G  120K   14G   1% /home/jovyan/.saturn\r\n",
      "tmpfs            14G   12K   14G   1% /run/secrets/kubernetes.io/serviceaccount\r\n",
      "tmpfs           7.7G   12K  7.7G   1% /proc/driver/nvidia\r\n",
      "tmpfs           7.7G  4.7M  7.7G   1% /run/nvidia-persistenced/socket\r\n",
      "tmpfs           7.7G     0  7.7G   0% /proc/acpi\r\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/firmware\r\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e104da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline( \n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    ") \n",
    "\n",
    "generation_args = { \n",
    "    \"max_new_tokens\": 500, \n",
    "    \"return_full_text\": False, \n",
    "    \"temperature\": 0.0, \n",
    "    \"do_sample\": False, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57bfe334",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# # Define generation arguments\n",
    "# generation_args = {\n",
    "#     \"max_new_tokens\": 500,\n",
    "#     \"return_full_text\": False,\n",
    "#     \"temperature\": 0.7, \n",
    "#     \"do_sample\": True,  \n",
    "# }\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.9,  # Increase temperature for more creativity\n",
    "    \"top_k\": 50,         # Limits the sampling pool to the top 50 tokens\n",
    "    \"do_sample\": True,  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "143a9e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: result = [{'generated_text': \"\\n        Question 1: Can you describe any specific situations or triggers that lead to you hitting your head?\\n        Question 2: How do you feel emotionally before, during, and after the act of hitting your head?\\n        Question 3: Have you tried any coping mechanisms or strategies in the past to help manage your anxiety and prevent self-harm? If so, what were they and how effective were they?\\n\\n        In this case, the questions are designed to help the individual understand the underlying causes of their behavior, their emotional state during the act, and any previous attempts at managing their anxiety and self-harm tendencies. By gathering this information, a mental health professional can better tailor a treatment plan to address the individual's specific needs and challenges.\\nB: Question 1: Can you tell me more about your childhood experiences and how they might be connected to your current behavior?\\n\\nQuestion 2: How do you feel when you hit your head? Do you notice any physical or emotional sensations that occur before, during, or after the act?\\n\\nQuestion 3: Have you ever tried to stop hitting your head? If so, what strategies have you used and how effective have they been?\\n\\nIn this case, the questions are designed to help the individual explore the potential links between their childhood experiences and current behavior, understand their emotional and physical sensations related to self-harm, and identify any previous attempts at stopping the behavior and their effectiveness. By gathering this information, a mental health professional can better understand the individual's unique situation and develop a personalized treatment plan to address their needs and challenges.\\n\\n\\n## Response:\\nQuestion 1: Can you describe any specific situations or triggers that lead to you hitting your head?\\n\\nQuestion 2: How do you feel emotionally before, during, and after the act of hitting your head?\\n\\nQuestion 3: Have you tried any coping mechanisms or strategies in the past to help manage your anxiety and prevent self-harm? If so, what were they and how effective were they?\\n\\nIn this case, the questions are designed to help the individual understand the underlying causes of their behavior, their emotional state during the act, and any previous attempts at managing their anxiety and self-harm tendencies. By\"}]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_questions\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Generate questions\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m questions_list \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 41\u001b[0m, in \u001b[0;36mgenerate_questions\u001b[0;34m(df, num_questions, sample_size)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Check the structure of result\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDebug: result = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m     generated_text \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m generated_text:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Missing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for result \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import pandas as pd\n",
    "\n",
    "# Define the function to generate questions with unique IDs\n",
    "def generate_questions(df, num_questions=3, sample_size=500):\n",
    "    # Sample 500 records from the DataFrame\n",
    "    sample_df = df.sample(n=sample_size, random_state=42)\n",
    "    prompts = []\n",
    "    context_ids = {}\n",
    "\n",
    "    for index, row in sample_df.iterrows():\n",
    "        context = row['Context']\n",
    "        context_id = str(uuid.uuid4())  # Generate a unique ID for each context\n",
    "        context_ids[context] = context_id\n",
    "        \n",
    "        # Prepare the prompt\n",
    "        prompt = f\"\"\"\n",
    "        You are emulating a person experiencing mental health challenges.\n",
    "        Formulate {num_questions} insightful questions based on the following mental health conversation record. Use the context provided to generate relevant questions.\n",
    "\n",
    "        Record:\n",
    "        Context: {context}\n",
    "\n",
    "        Provide the output in a format that can be easily parsed from a dataframe:\n",
    "        \"Question 1\"\n",
    "        \"Question 2\"\n",
    "        \"Question 3\"\n",
    "        \"\"\"\n",
    "        \n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    all_questions = []\n",
    "    for i in range(0, len(prompts), 50):  # Batch size of 50\n",
    "        batch_prompts = prompts[i:i+50]\n",
    "        results = pipe(batch_prompts, **generation_args)\n",
    "        \n",
    "        for index, result in enumerate(results):\n",
    "            # Check the structure of result\n",
    "            print(f\"Debug: result = {result}\")\n",
    "            \n",
    "            generated_text = result.get('generated_text', '')\n",
    "            if not generated_text:\n",
    "                print(f\"Warning: Missing 'generated_text' for result {index} in batch {i // 50}\")\n",
    "                continue  # Skip this result if 'generated_text' is missing\n",
    "            \n",
    "            # Split the result into individual questions\n",
    "            questions = generated_text.strip().split('\\n')\n",
    "            \n",
    "            # Clean the questions and take the required number of questions\n",
    "            questions = [q.strip('\"') for q in questions if q.strip()][:num_questions]\n",
    "            \n",
    "            # Ensure we have exactly num_questions (fill with empty strings if not enough)\n",
    "            while len(questions) < num_questions:\n",
    "                questions.append(\"\")\n",
    "            \n",
    "            # Retrieve the context ID and add the questions to the list\n",
    "            context = sample_df.iloc[i + index]['Context']\n",
    "            context_id = context_ids[context]\n",
    "            \n",
    "            for j, question in enumerate(questions):\n",
    "                all_questions.append({\n",
    "                    'Question': question,\n",
    "                    'document': f\"{context_id}_q{j+1}\"  # Use 'document' as the column name\n",
    "                })\n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "# Generate questions\n",
    "questions_list = generate_questions(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b7e2d52",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_questions\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Generate questions\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m questions_list \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 38\u001b[0m, in \u001b[0;36mgenerate_questions\u001b[0;34m(df, num_questions, sample_size)\u001b[0m\n\u001b[1;32m     34\u001b[0m results \u001b[38;5;241m=\u001b[39m pipe(batch_prompts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgeneration_args)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# Access the generated text from the result dictionary\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     generated_text \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenerated_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Split the result into individual questions\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     questions \u001b[38;5;241m=\u001b[39m generated_text\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import pandas as pd\n",
    "\n",
    "# Define the function to generate questions with unique IDs\n",
    "def generate_questions(df, num_questions=3, sample_size=50):\n",
    "    # Sample 50 records from the DataFrame\n",
    "    sample_df = df.sample(n=sample_size, random_state=42)\n",
    "    prompts = []\n",
    "    context_ids = {}\n",
    "\n",
    "    for index, row in sample_df.iterrows():\n",
    "        context = row['Context']\n",
    "        context_id = str(uuid.uuid4())  # Generate a unique ID for each context\n",
    "        context_ids[context] = context_id\n",
    "        \n",
    "        # Prepare the prompt\n",
    "        prompt = f\"\"\"\n",
    "        You are emulating a person experiencing mental health challenges.\n",
    "        Formulate {num_questions} insightful questions based on the following mental health conversation record. \n",
    "        Use the context provided to generate relevant questions.\n",
    "\n",
    "        Record:\n",
    "        Context: {context}\n",
    "\n",
    "        Provide the output in a format that can be easily parsed from a dataframe:\n",
    "        \"Question 1\", \"Question 2\", \"Question 3\"\n",
    "        \"\"\"\n",
    "        \n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    all_questions = []\n",
    "    for i in range(0, len(prompts), 10):  # Batch size of 10\n",
    "        batch_prompts = prompts[i:i+10]\n",
    "        results = pipe(batch_prompts, **generation_args)\n",
    "        \n",
    "        for index, result in enumerate(results):\n",
    "            # Access the generated text from the result dictionary\n",
    "            generated_text = result['generated_text']\n",
    "            \n",
    "            # Split the result into individual questions\n",
    "            questions = generated_text.strip().split('\\n')\n",
    "            \n",
    "            # Clean the questions and take the required number of questions\n",
    "            questions = [q.strip('\"') for q in questions if q.strip()][:num_questions]\n",
    "            \n",
    "            # Ensure we have exactly num_questions (fill with empty strings if not enough)\n",
    "            while len(questions) < num_questions:\n",
    "                questions.append(\"\")\n",
    "            \n",
    "            # Retrieve the context ID and add the questions to the list\n",
    "            context = sample_df.iloc[i + index]['Context']\n",
    "            context_id = context_ids[context]\n",
    "            \n",
    "            for j, question in enumerate(questions):\n",
    "                all_questions.append({\n",
    "                    'Question': question,\n",
    "                    'document': f\"{context_id}_q{j+1}\"  # Use 'document' as the column name\n",
    "                })\n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "# Generate questions\n",
    "questions_list = generate_questions(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "370b76f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: results = [{'generated_text': 'Question 1\\nQuestion 2\\nQuestion 3'}, {'generated_text': 'Question 1\\nQuestion 2\\nQuestion 3'}, {'generated_text': 'Question 1\\nQuestion 2\\nQuestion 3'}, {'generated_text': 'Question 1\\nQuestion 2\\nQuestion 3'}, {'generated_text': 'Question 1\\nQuestion 2\\nQuestion 3'}]\n",
      "[{'Question': 'Question 1', 'document': 'ee7b38b2-336d-4457-a340-de5dcd1fc86c_q1'}, {'Question': 'Question 2', 'document': 'ee7b38b2-336d-4457-a340-de5dcd1fc86c_q2'}, {'Question': 'Question 3', 'document': 'ee7b38b2-336d-4457-a340-de5dcd1fc86c_q3'}, {'Question': 'Question 1', 'document': '4ba5add5-3132-437e-bfdf-d6a2bcb3cb18_q1'}, {'Question': 'Question 2', 'document': '4ba5add5-3132-437e-bfdf-d6a2bcb3cb18_q2'}, {'Question': 'Question 3', 'document': '4ba5add5-3132-437e-bfdf-d6a2bcb3cb18_q3'}, {'Question': 'Question 1', 'document': 'b1ec2eda-f8e7-46bb-9f4b-80eb50377f04_q1'}, {'Question': 'Question 2', 'document': 'b1ec2eda-f8e7-46bb-9f4b-80eb50377f04_q2'}, {'Question': 'Question 3', 'document': 'b1ec2eda-f8e7-46bb-9f4b-80eb50377f04_q3'}, {'Question': 'Question 1', 'document': '0917e298-6698-4566-9f99-ecedf8f1ef71_q1'}, {'Question': 'Question 2', 'document': '0917e298-6698-4566-9f99-ecedf8f1ef71_q2'}, {'Question': 'Question 3', 'document': '0917e298-6698-4566-9f99-ecedf8f1ef71_q3'}, {'Question': 'Question 1', 'document': '41d7543b-8971-445c-9215-d199c58d6b91_q1'}, {'Question': 'Question 2', 'document': '41d7543b-8971-445c-9215-d199c58d6b91_q2'}, {'Question': 'Question 3', 'document': '41d7543b-8971-445c-9215-d199c58d6b91_q3'}]\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import pandas as pd\n",
    "\n",
    "# Define the function to generate questions with unique IDs\n",
    "def generate_questions(df, num_questions=3, sample_size=10):\n",
    "    # Sample 50 records from the DataFrame\n",
    "    sample_df = df.sample(n=sample_size, random_state=42)\n",
    "    prompts = []\n",
    "    context_ids = {}\n",
    "\n",
    "    for index, row in sample_df.iterrows():\n",
    "        context = row['Context']\n",
    "        context_id = str(uuid.uuid4())  # Generate a unique ID for each context\n",
    "        context_ids[context] = context_id\n",
    "        \n",
    "        # Prepare the prompt\n",
    "        prompt = f\"\"\"\n",
    "        You are emulating a person experiencing mental health challenges.\n",
    "        Formulate {num_questions} insightful questions based on the following mental health conversation record. \n",
    "        Use the context provided to generate relevant questions.\n",
    "\n",
    "        Record:\n",
    "        Context: {context}\n",
    "\n",
    "        Provide the output in a format that can be easily parsed from a dataframe:\n",
    "        \"Question 1\", \"Question 2\", \"Question 3\"\n",
    "        \"\"\"\n",
    "        \n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    all_questions = []\n",
    "    for i in range(0, len(prompts), 5):  # Batch size of 10\n",
    "        batch_prompts = prompts[i:i+5]\n",
    "        results = pipe(batch_prompts, **generation_args)\n",
    "        \n",
    "        # Debug: Print the structure of results\n",
    "        print(f\"Debug: results = {results}\")\n",
    "        \n",
    "        for index, result in enumerate(results):\n",
    "            if isinstance(result, dict) and 'generated_text' in result:\n",
    "                generated_text = result['generated_text']\n",
    "            else:\n",
    "                print(f\"Unexpected result format: {result}\")\n",
    "                continue\n",
    "            \n",
    "            # Split the result into individual questions\n",
    "            questions = generated_text.strip().split('\\n')\n",
    "            \n",
    "            # Clean the questions and take the required number of questions\n",
    "            questions = [q.strip('\"') for q in questions if q.strip()][:num_questions]\n",
    "            \n",
    "            # Ensure we have exactly num_questions (fill with empty strings if not enough)\n",
    "            while len(questions) < num_questions:\n",
    "                questions.append(\"\")\n",
    "            \n",
    "            # Retrieve the context ID and add the questions to the list\n",
    "            context = sample_df.iloc[i + index % 5]['Context']\n",
    "            context_id = context_ids[context]\n",
    "            \n",
    "            for j, question in enumerate(questions):\n",
    "                all_questions.append({\n",
    "                    'Question': question,\n",
    "                    'document': f\"{context_id}_q{j+1}\"  # Use 'document' as the column name\n",
    "                })\n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "# Mocking the df and pipe function for testing purposes\n",
    "df = pd.DataFrame({\n",
    "    'Context': [\"Context 1\", \"Context 2\", \"Context 3\", \"Context 4\", \"Context 5\"]\n",
    "})\n",
    "\n",
    "# Mocking the pipe function to return expected structure\n",
    "def pipe(prompts, **kwargs):\n",
    "    return [{'generated_text': 'Question 1\\nQuestion 2\\nQuestion 3'} for _ in prompts]\n",
    "\n",
    "# Generation arguments (mocked for testing purposes)\n",
    "generation_args = {}\n",
    "\n",
    "# Generate questions\n",
    "questions_list = generate_questions(df, num_questions=3, sample_size=5)\n",
    "print(questions_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e73902c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Example usage with DataFrame\u001b[39;00m\n\u001b[1;32m     65\u001b[0m sample_df \u001b[38;5;241m=\u001b[39m df1\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m questions_list \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m questions_list:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 46\u001b[0m, in \u001b[0;36mgenerate_questions\u001b[0;34m(sample_df, num_questions)\u001b[0m\n\u001b[1;32m     36\u001b[0m remaining_questions \u001b[38;5;241m=\u001b[39m num_questions \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(questions)\n\u001b[1;32m     37\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124mGenerate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremaining_questions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m more questions based on the following context:\u001b[39m\n\u001b[1;32m     39\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124mQuestion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(questions)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: [Your question here]\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 46\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_args\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     48\u001b[0m     question_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(questions) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[13], line 75\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(prompts, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpipe\u001b[39m(prompts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestion 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion 3\u001b[39m\u001b[38;5;124m'\u001b[39m} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m prompts]\n",
      "Cell \u001b[0;32mIn[13], line 75\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpipe\u001b[39m(prompts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestion 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion 3\u001b[39m\u001b[38;5;124m'\u001b[39m} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m prompts]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def generate_questions(sample_df, num_questions=3):\n",
    "    all_questions = []\n",
    "\n",
    "    for index, row in sample_df.iterrows():\n",
    "        context = row['Context']\n",
    "        response = row['Response']\n",
    "        \n",
    "        # Prepare the prompt\n",
    "        prompt = f\"\"\"\n",
    "        You are emulating a person experiencing mental health challenges.\n",
    "        Formulate {num_questions} insightful questions based on the following mental health conversation record. Use the context provided to generate relevant questions, but avoid directly copying words from the response.\n",
    "\n",
    "        Record:\n",
    "        Context: {context}\n",
    "        Response: {response}\n",
    "\n",
    "        Provide the output in a format that can be easily parsed from a dataframe:\n",
    "        \"Question 1\", \"Question 2\", \"Question 3\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate the questions using the pipeline\n",
    "        result = pipe(prompt, **generation_args)[0][\"generated_text\"]\n",
    "        \n",
    "        # Extract questions from the generated text\n",
    "        questions = []\n",
    "        for line in result.split('\\n'):\n",
    "            if 'Question' in line:\n",
    "                parts = line.split(\":\", 1)\n",
    "                if len(parts) > 1:\n",
    "                    question_text = parts[1].strip()\n",
    "                    if question_text:\n",
    "                        questions.append(question_text)\n",
    "        \n",
    "        # Ensure we have exactly num_questions, regenerate if needed\n",
    "        while len(questions) < num_questions:\n",
    "            remaining_questions = num_questions - len(questions)\n",
    "            prompt = f\"\"\"\n",
    "            Generate {remaining_questions} more questions based on the following context:\n",
    "\n",
    "            Context: {context}\n",
    "            Response: {response}\n",
    "\n",
    "            Provide the output in the following format:\n",
    "            Question {len(questions) + 1}: [Your question here]\n",
    "            \"\"\"\n",
    "            result = pipe(prompt, **generation_args)[0][\"generated_text\"]\n",
    "            for line in result.split('\\n'):\n",
    "                question_num = len(questions) + 1\n",
    "                if f'Question {question_num}' in line:\n",
    "                    parts = line.split(\":\", 1)\n",
    "                    if len(parts) > 1:\n",
    "                        question_text = parts[1].strip()\n",
    "                        if question_text:\n",
    "                            questions.append(question_text)\n",
    "        \n",
    "        # Add the questions to the list with their corresponding context\n",
    "        all_questions.append({\n",
    "            'Context': context,\n",
    "            'Questions': questions\n",
    "        })\n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "# Example usage with DataFrame\n",
    "sample_df = df1.sample(n=3, random_state=42)\n",
    "\n",
    "questions_list = generate_questions(sample_df)\n",
    "for record in questions_list:\n",
    "    print(f\"Context: {record['Context']}\")\n",
    "    for i, question in enumerate(record['Questions'], 1):\n",
    "        print(f\"Question {i}: {question}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e3416f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>If everyone thinks you're worthless, then mayb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  I'm going through some things with my feelings...   \n",
       "\n",
       "                                            Response  \n",
       "0  If everyone thinks you're worthless, then mayb...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = dataset.to_pandas()\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8a9f431",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Example usage with DataFrame\u001b[39;00m\n\u001b[1;32m     65\u001b[0m sample_df \u001b[38;5;241m=\u001b[39m df1\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m questions_list \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m questions_list:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 46\u001b[0m, in \u001b[0;36mgenerate_questions\u001b[0;34m(sample_df, num_questions)\u001b[0m\n\u001b[1;32m     36\u001b[0m remaining_questions \u001b[38;5;241m=\u001b[39m num_questions \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(questions)\n\u001b[1;32m     37\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124mGenerate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremaining_questions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m more questions based on the following context:\u001b[39m\n\u001b[1;32m     39\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124mQuestion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(questions)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: [Your question here]\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 46\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_args\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     48\u001b[0m     question_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(questions) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[13], line 75\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(prompts, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpipe\u001b[39m(prompts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestion 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion 3\u001b[39m\u001b[38;5;124m'\u001b[39m} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m prompts]\n",
      "Cell \u001b[0;32mIn[13], line 75\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpipe\u001b[39m(prompts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestion 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion 3\u001b[39m\u001b[38;5;124m'\u001b[39m} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m prompts]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def generate_questions(sample_df, num_questions=3):\n",
    "    all_questions = []\n",
    "\n",
    "    for index, row in sample_df.iterrows():\n",
    "        context = row['Context']\n",
    "        response = row['Response']\n",
    "        \n",
    "        # Prepare the prompt\n",
    "        prompt = f\"\"\"\n",
    "        You are emulating a person experiencing mental health challenges.\n",
    "        Formulate {num_questions} insightful questions based on the following mental health conversation record. Use the context provided to generate relevant questions, but avoid directly copying words from the response.\n",
    "\n",
    "        Record:\n",
    "        Context: {context}\n",
    "        Response: {response}\n",
    "\n",
    "        Provide the output in a format that can be easily parsed from a dataframe:\n",
    "        \"Question 1\", \"Question 2\", \"Question 3\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate the questions using the pipeline\n",
    "        result = pipe(prompt, **generation_args)[0][\"generated_text\"]\n",
    "        \n",
    "        # Extract questions from the generated text\n",
    "        questions = []\n",
    "        for line in result.split('\\n'):\n",
    "            if 'Question' in line:\n",
    "                parts = line.split(\":\", 1)\n",
    "                if len(parts) > 1:\n",
    "                    question_text = parts[1].strip()\n",
    "                    if question_text:\n",
    "                        questions.append(question_text)\n",
    "        \n",
    "        # Ensure we have exactly num_questions, regenerate if needed\n",
    "        while len(questions) < num_questions:\n",
    "            remaining_questions = num_questions - len(questions)\n",
    "            prompt = f\"\"\"\n",
    "            Generate {remaining_questions} more questions based on the following context:\n",
    "\n",
    "            Context: {context}\n",
    "            Response: {response}\n",
    "\n",
    "            Provide the output in the following format:\n",
    "            Question {len(questions) + 1}: [Your question here]\n",
    "            \"\"\"\n",
    "            result = pipe(prompt, **generation_args)[0][\"generated_text\"]\n",
    "            for line in result.split('\\n'):\n",
    "                question_num = len(questions) + 1\n",
    "                if f'Question {question_num}' in line:\n",
    "                    parts = line.split(\":\", 1)\n",
    "                    if len(parts) > 1:\n",
    "                        question_text = parts[1].strip()\n",
    "                        if question_text:\n",
    "                            questions.append(question_text)\n",
    "        \n",
    "        # Ensure we only add the required number of questions\n",
    "        all_questions.append({\n",
    "            'Context': context,\n",
    "            'Questions': questions[:num_questions]\n",
    "        })\n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "# Example usage with DataFrame\n",
    "sample_df = df1.sample(n=3, random_state=42)\n",
    "\n",
    "questions_list = generate_questions(sample_df)\n",
    "for record in questions_list:\n",
    "    print(f\"Context: {record['Context']}\")\n",
    "    for i, question in enumerate(record['Questions'], 1):\n",
    "        print(f\"Question {i}: {question}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbc3d27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: I've hit my head on walls and floors ever since I was young. I sometimes still do it but I don't exactly know why,    I have anxiety and I had a rough childhood but now I'll start to hit my head and sometimes not realize it but I don't know how to stop or even why I'm doing it.    How can I help myself to change my behavior?\n",
      "Question 1: What specific triggers or situations make you more likely to hit your head, and how can you identify these patterns?\",\n",
      "Question 2: Can you describe the thoughts or emotions that precede the act of hitting your head, and how might these be addressed in therapy?\",\n",
      "Question 3: What positive behaviors or activities have you found to be helpful in managing your anxiety and preventing the urge to hit your head?\"\n",
      "Question 4: In what ways have your past experiences, particularly your childhood, shaped your current coping mechanisms, and how can we work together to develop healthier strategies for dealing with stress and anxiety?\",\n",
      "Question 5: How do you feel when you realize you're about to hit your head, and what steps can you take to interrupt this cycle and replace it with a more constructive response?\",\n",
      "Question 6: Can you share any moments or activities in the past that brought you a sense of relief or calm, and how might we incorporate similar elements into your daily routine to help manage your anxiety?\"\n",
      "\n",
      "Context: Over a year ago I had a female friend. She turned out to be kind of crazy so I decided to stop talking to her. When she would call me I wouldn't answer the phone. This made my girlfriend really suspicious. She would ask me why I wouldn't ever answer that phone number. I told my girlfriend that I don't want to be friends with that other woman, but I don't think she believes me. How can I get my girlfriend to understand?\n",
      "Question 1: Can you share more about your past interactions with the other woman and why you felt the need to end the friendship?\",\n",
      "Question 2: How do you plan to reassure your girlfriend that your relationship is secure and that you value her above all others?\",\n",
      "Question 3: What specific actions can you take to demonstrate your love and commitment to your girlfriend, and how can you communicate these to her effectively?\"\n",
      "\n",
      "Context: My long-distance girlfriend is in a sorority, and it's changing her. I feel like I'm becoming less important to her and it hurts. She just wants me to support the sorority, but it's so hard. I try every day to show her she's the most important thing to me, but she can't even stay relatively sober at a fraternity party for me so that I won't worry about her doing anything regretful. We love each other, but we're in a rough patch.\n",
      "Question 1: What specific aspects of your relationship do you both value the most, and how do these align with your current challenges?\n",
      "Question 2: How do you each envision the future of your relationship, and what steps can you take to work towards that vision together?\n",
      "Question 3: In what ways can you both support each other's individual interests and responsibilities while maintaining a strong connection as a couple?\n",
      "Question 4: What specific aspects of your relationship do you both value the most, and how do these align with your current challenges?\n",
      "Question 5: How do you each envision the future of your relationship, and what steps can you take to work towards that vision together?\n",
      "Question 6: In what ways can you both support each other's individual interests and responsibilities while maintaining a strong connection as a couple?\n",
      "Question 7: How do you each define the balance of contributions to your relationship, and in what ways do you feel this balance is currently being affected by the situation with the sorority?\n",
      "Question 8: Can you both identify the core values that brought you together initially, and discuss how these values are being challenged or upheld in the current situation?\n",
      "Question 9: What are some strategies you both have tried or could consider to ensure open and honest communication about your concerns and expectations, especially in relation to the sorority's influence on your relationship?\n",
      "Question 10: How do you each define the balance of contributions to your relationship, and in what ways do you feel this balance is currently being affected by the situation with the sorority?\n",
      "Question 11: Can you both identify the core values that brought you together initially, and discuss how these values are being challenged or upheld in the current situation?\n",
      "Question 12: What are some strategies you both have tried or could consider to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_questions(sample_df, num_questions=3):\n",
    "    all_questions = []\n",
    "\n",
    "    for index, row in sample_df.iterrows():\n",
    "        context = row['Context']\n",
    "        response = row['Response']\n",
    "        \n",
    "        # Prepare the prompt to generate all questions in one go\n",
    "        prompt = f\"\"\"\n",
    "        You are emulating a person experiencing mental health challenges.\n",
    "        Formulate {num_questions} insightful questions based on the following mental health conversation record. Use the context provided to generate relevant questions, but avoid directly copying words from the response.\n",
    "\n",
    "        Record:\n",
    "        Context: {context}\n",
    "        Response: {response}\n",
    "\n",
    "        Provide the output in a format that can be easily parsed from a dataframe:\n",
    "        \"Question 1\", \"Question 2\", \"Question 3\"\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate the questions using the pipeline\n",
    "        result = pipe(prompt, **generation_args)[0][\"generated_text\"]\n",
    "\n",
    "        # Extract questions from the generated text\n",
    "        questions = []\n",
    "        for line in result.split('\\n'):\n",
    "            if 'Question' in line:\n",
    "                parts = line.split(\":\", 1)\n",
    "                if len(parts) > 1:\n",
    "                    question_text = parts[1].strip()\n",
    "                    if question_text:\n",
    "                        questions.append(question_text)\n",
    "        \n",
    "        # Ensure we have exactly num_questions\n",
    "        while len(questions) < num_questions:\n",
    "            remaining_questions = num_questions - len(questions)\n",
    "            prompt = f\"\"\"\n",
    "            Generate {remaining_questions} more questions based on the following context:\n",
    "\n",
    "            Context: {context}\n",
    "            Response: {response}\n",
    "\n",
    "            Provide the output in the following format:\n",
    "            Question {len(questions) + 1}: [Your question here]\n",
    "            \"\"\"\n",
    "            result = pipe(prompt, **generation_args)[0][\"generated_text\"]\n",
    "            for line in result.split('\\n'):\n",
    "                question_num = len(questions) + 1\n",
    "                if f'Question {question_num}' in line:\n",
    "                    parts = line.split(\":\", 1)\n",
    "                    if len(parts) > 1:\n",
    "                        question_text = parts[1].strip()\n",
    "                        if question_text:\n",
    "                            questions.append(question_text)\n",
    "        \n",
    "        # Add the questions to the list with their corresponding context\n",
    "        all_questions.append({\n",
    "            'Context': context,\n",
    "            'Questions': questions\n",
    "        })\n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "# Example usage with DataFrame\n",
    "sample_df = df1.sample(n=3, random_state=42)\n",
    "\n",
    "questions_list = generate_questions(sample_df)\n",
    "for record in questions_list:\n",
    "    print(f\"Context: {record['Context']}\")\n",
    "    for i, question in enumerate(record['Questions'], 1):\n",
    "        print(f\"Question {i}: {question}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "895a6613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: I've hit my head on walls and floors ever since I was young. I sometimes still do it but I don't exactly know why,    I have anxiety and I had a rough childhood but now I'll start to hit my head and sometimes not realize it but I don't know how to stop or even why I'm doing it.    How can I help myself to change my behavior?\n",
      "Question 1: \"What specific type of therapy has been proven helpful for depression and anxiety?\", \"Question 2\": \"What is the role of medication in managing severe anxiety?\", \"Question 3\": \"Why is it not recommended to try to manage severe anxiety without professional help?\", \"Question 4\": \"What is the difference between Cognitive Behavioral Therapy and trauma informed therapy?\", \"Question 5\": \"How can one learn to recognize and deal with the underlying cause of a harmful behavior?\", \"Question 6\": \"What are some positive behaviors that can replace the harmful behavior of hitting one's head?\"}\n",
      "Question 2: What are some positive behaviors that can replace the harmful behavior of hitting one's head?\n",
      "Question 3: What is the difference between Cognitive Behavioral Therapy and trauma informed therapy?\n",
      "\n",
      "Context: Over a year ago I had a female friend. She turned out to be kind of crazy so I decided to stop talking to her. When she would call me I wouldn't answer the phone. This made my girlfriend really suspicious. She would ask me why I wouldn't ever answer that phone number. I told my girlfriend that I don't want to be friends with that other woman, but I don't think she believes me. How can I get my girlfriend to understand?\n",
      "Question 1: What steps have you taken to address your girlfriend's concerns about your friendship with the other woman?\n",
      "Question 2: What steps have you taken to address your girlfriend's concerns about your friendship with the other woman?\n",
      "Question 3: What steps have you taken to address your girlfriend's concerns about your friendship with the other woman?\n",
      "\n",
      "Context: My long-distance girlfriend is in a sorority, and it's changing her. I feel like I'm becoming less important to her and it hurts. She just wants me to support the sorority, but it's so hard. I try every day to show her she's the most important thing to me, but she can't even stay relatively sober at a fraternity party for me so that I won't worry about her doing anything regretful. We love each other, but we're in a rough patch.\n",
      "Question 1: In the context of the mental health conversation record provided, generate six insightful questions that delve deeper into the couple's situation. The questions should be designed to help the couple understand their relationship dynamics better and should not directly replicate the content of the response. The questions should be formatted as a list, with each question starting with \"Question\" followed by a sequential number and a colon. Ensure that the questions are open-ended and encourage reflection and discussion between the couple.\n",
      "Question 2: What are the core values that both of you hold dear in your relationship, and how do these values align or conflict with the activities and commitments your partner has with the sorority?\n",
      "Question 3: Have you both had the opportunity to express your concerns and expectations regarding your partner's involvement in the sorority, and if so, what were the outcomes of these discussions?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def score_questions(questions, context):\n",
    "    # Dummy scoring function; you can replace this with a more sophisticated method\n",
    "    scores = []\n",
    "    for question in questions:\n",
    "        # Simple scoring: length of question relative to context length\n",
    "        score = len(question) / len(context)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def generate_questions(sample_df, num_questions=3):\n",
    "    all_questions = []\n",
    "\n",
    "    for index, row in sample_df.iterrows():\n",
    "        context = row['Context']\n",
    "        response = row['Response']\n",
    "        \n",
    "        # Prepare the prompt to generate all questions in one go\n",
    "        prompt = f\"\"\"\n",
    "        You are emulating a person experiencing mental health challenges.\n",
    "        Formulate {num_questions*2} insightful questions based on the following mental health conversation record. Use the context provided to generate relevant questions, but avoid directly copying words from the response.\n",
    "\n",
    "        Record:\n",
    "        Context: {context}\n",
    "        Response: {response}\n",
    "\n",
    "        Provide the output in a format that can be easily parsed from a dataframe:\n",
    "        \"Question 1\", \"Question 2\", \"Question 3\", ...\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate the questions using the pipeline\n",
    "        result = pipe(prompt, **generation_args)[0][\"generated_text\"]\n",
    "\n",
    "        # Extract questions from the generated text\n",
    "        questions = []\n",
    "        for line in result.split('\\n'):\n",
    "            if 'Question' in line:\n",
    "                parts = line.split(\":\", 1)\n",
    "                if len(parts) > 1:\n",
    "                    question_text = parts[1].strip()\n",
    "                    if question_text:\n",
    "                        questions.append(question_text)\n",
    "        \n",
    "        # Score and select top num_questions questions\n",
    "        if len(questions) > num_questions:\n",
    "            scores = score_questions(questions, context)\n",
    "            sorted_questions = [q for _, q in sorted(zip(scores, questions), reverse=True)]\n",
    "            selected_questions = sorted_questions[:num_questions]\n",
    "        else:\n",
    "            selected_questions = questions\n",
    "        \n",
    "        # Add the questions to the list with their corresponding context\n",
    "        all_questions.append({\n",
    "            'Context': context,\n",
    "            'Questions': selected_questions\n",
    "        })\n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "# Example usage with DataFrame\n",
    "sample_df = df1.sample(n=3, random_state=42)\n",
    "\n",
    "questions_list = generate_questions(sample_df)\n",
    "for record in questions_list:\n",
    "    print(f\"Context: {record['Context']}\")\n",
    "    for i, question in enumerate(record['Questions'], 1):\n",
    "        print(f\"Question {i}: {question}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c033ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: I've hit my head on walls and floors ever since I was young. I sometimes still do it but I don't exactly know why,    I have anxiety and I had a rough childhood but now I'll start to hit my head and sometimes not realize it but I don't know how to stop or even why I'm doing it.    How can I help myself to change my behavior?\n",
      "Question 1: In what ways do you feel supported by your friends, family, or others in your life, and how do you think you could open up about your struggles to them?\"\n",
      "Question 2: Are there certain times of day or specific situations where you feel more inclined to hit your head, and if so, what might be triggering those moments?\"\n",
      "Question 3: Have you noticed any patterns or recurring themes in your life that might be connected to the anxiety and self-harming behaviors you've experienced?\"\n",
      "\n",
      "Context: Over a year ago I had a female friend. She turned out to be kind of crazy so I decided to stop talking to her. When she would call me I wouldn't answer the phone. This made my girlfriend really suspicious. She would ask me why I wouldn't ever answer that phone number. I told my girlfriend that I don't want to be friends with that other woman, but I don't think she believes me. How can I get my girlfriend to understand?\n",
      "Question 1: What are some ways you can show your girlfriend that she is your priority and the most important person in your life, and how do you think this could alleviate her worries about your past interactions with your female friend?\n",
      "Question 2: What are the core values and beliefs you want your girlfriend to have about your relationship, and how do you think opening up about your past with your female friend can reinforce those values?\n",
      "Question 3: Have you and your girlfriend had a candid conversation about trust and communication within your relationship? If not, how do you think that conversation could help address her concerns?\n",
      "\n",
      "Context: My long-distance girlfriend is in a sorority, and it's changing her. I feel like I'm becoming less important to her and it hurts. She just wants me to support the sorority, but it's so hard. I try every day to show her she's the most important thing to me, but she can't even stay relatively sober at a fraternity party for me so that I won't worry about her doing anything regretful. We love each other, but we're in a rough patch.\n",
      "Question 1: How can you show your girlfriend that she is the most important thing in your eyes beyond just staying sober at parties?\"\n",
      "Question 2: How can you show your girlfriend that she is the most important thing in your eyes beyond just staying sober at parties?\n",
      "Question 3: How can you show your girlfriend that she is the most important thing in your eyes beyond just staying sober at parties?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def score_questions(questions, context):\n",
    "    # Improved scoring function; can be customized\n",
    "    scores = []\n",
    "    for question in questions:\n",
    "        # Basic scoring: consider length and relevance\n",
    "        score = len(question) / len(context)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def generate_questions(sample_df, num_questions=3):\n",
    "    all_questions = []\n",
    "\n",
    "    for _, row in sample_df.iterrows():\n",
    "        context = row['Context']\n",
    "        response = row['Response']\n",
    "        \n",
    "        # Prepare the prompt\n",
    "        prompt = f\"\"\"\n",
    "        You are emulating a person experiencing mental health challenges.\n",
    "        Formulate {num_questions*2} insightful questions based on the following mental health conversation record. \n",
    "        Use the context provided to generate relevant questions, but avoid directly copying words from the response.\n",
    "\n",
    "        Record:\n",
    "        Context: {context}\n",
    "        Response: {response}\n",
    "\n",
    "        Provide the output in the format:\n",
    "        \"Question 1: Question text\"\n",
    "        \"Question 2: Question text\"\n",
    "        ...\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate the questions\n",
    "        result = pipe(prompt, **generation_args)[0][\"generated_text\"]\n",
    "\n",
    "        # Extract questions\n",
    "        questions = []\n",
    "        for line in result.split('\\n'):\n",
    "            if 'Question' in line:\n",
    "                parts = line.split(\":\", 1)\n",
    "                if len(parts) > 1:\n",
    "                    question_text = parts[1].strip()\n",
    "                    if question_text:\n",
    "                        questions.append(question_text)\n",
    "        \n",
    "        # Score and select top num_questions questions\n",
    "        if len(questions) > num_questions:\n",
    "            scores = score_questions(questions, context)\n",
    "            sorted_questions = [q for _, q in sorted(zip(scores, questions), reverse=True)]\n",
    "            selected_questions = sorted_questions[:num_questions]\n",
    "        else:\n",
    "            selected_questions = questions\n",
    "        \n",
    "        # Add the questions to the list with their corresponding context\n",
    "        all_questions.append({\n",
    "            'Context': context,\n",
    "            'Questions': selected_questions\n",
    "        })\n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "# Example usage with DataFrame\n",
    "sample_df = df1.sample(n=3, random_state=42)\n",
    "\n",
    "questions_list = generate_questions(sample_df)\n",
    "for record in questions_list:\n",
    "    print(f\"Context: {record['Context']}\")\n",
    "    for i, question in enumerate(record['Questions'], 1):\n",
    "        print(f\"Question {i}: {question}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0f26732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: I've hit my head on walls and floors ever since I was young. I sometimes still do it but I don't exactly know why,    I have anxiety and I had a rough childhood but now I'll start to hit my head and sometimes not realize it but I don't know how to stop or even why I'm doing it.    How can I help myself to change my behavior?\n",
      "Question 1: What resources or support systems are available for someone like me, who is recognizing their mental health needs but uncertain about how to proceed with changing harmful habits?\"\n",
      "Question 2: Given that my childhood experiences might be influencing my current behavior, how can I seek therapy that acknowledges and treats trauma differently than general anxiety therapy?\"\n",
      "\n",
      "Context: Over a year ago I had a female friend. She turned out to be kind of crazy so I decided to stop talking to her. When she would call me I wouldn't answer the phone. This made my girlfriend really suspicious. She would ask me why I wouldn't ever answer that phone number. I told my girlfriend that I don't want to be friends with that other woman, but I don't think she believes me. How can I get my girlfriend to understand?\n",
      "Question 1: Have you considered ways to demonstrate the love and commitment you have for your girlfriend, reflecting shared experiences or gestures that remind her of your bond? Sometimes actions speak louder than words.\"\n",
      "Question 2: If you were to open up about your feelings, what specific assurances or evidence would help your girlfriend trust that your relationship is exclusive and nothing is being hidden?\"\n",
      "\n",
      "Context: My long-distance girlfriend is in a sorority, and it's changing her. I feel like I'm becoming less important to her and it hurts. She just wants me to support the sorority, but it's so hard. I try every day to show her she's the most important thing to me, but she can't even stay relatively sober at a fraternity party for me so that I won't worry about her doing anything regretful. We love each other, but we're in a rough patch.\n",
      "Question 1: In what ways might a professional therapist assist you in navigating the challenges presented by your girlfriend's involvement in the sorority?\"\n",
      "Question 2: How can you both approach difficult conversations about your emotional needs and the impact of your girlfriend's sorority activities?\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def generate_questions(sample_df, num_questions=2):\n",
    "    all_questions = []\n",
    "\n",
    "    for _, row in sample_df.iterrows():\n",
    "        context = row['Context']\n",
    "        response = row['Response']\n",
    "        \n",
    "        # Prepare the prompt\n",
    "        prompt = f\"\"\"\n",
    "        You are emulating a person experiencing mental health challenges.\n",
    "        Formulate {num_questions*2} insightful questions based on the following mental health conversation record. \n",
    "        Use the context provided to generate relevant questions, but avoid directly copying words from the response.\n",
    "\n",
    "        Record:\n",
    "        Context: {context}\n",
    "        Response: {response}\n",
    "\n",
    "        Provide the output in the format:\n",
    "        \"Question 1: Question text\"\n",
    "        \"Question 2: Question text\"\n",
    "        ...\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate the questions\n",
    "        result = pipe(prompt, **generation_args)[0][\"generated_text\"]\n",
    "\n",
    "        # Extract questions\n",
    "        questions = []\n",
    "        for line in result.split('\\n'):\n",
    "            if 'Question' in line:\n",
    "                parts = line.split(\":\", 1)\n",
    "                if len(parts) > 1:\n",
    "                    question_text = parts[1].strip()\n",
    "                    if question_text:\n",
    "                        questions.append(question_text)\n",
    "        \n",
    "        # Score and select top num_questions questions\n",
    "        if len(questions) > num_questions:\n",
    "            scores = score_questions(questions, context)\n",
    "            sorted_questions = [q for _, q in sorted(zip(scores, questions), reverse=True)]\n",
    "            selected_questions = sorted_questions[:num_questions]\n",
    "        else:\n",
    "            selected_questions = list(dict.fromkeys(questions))  # Remove duplicates if less than num_questions\n",
    "        \n",
    "        # Add the questions to the list with their corresponding context\n",
    "        all_questions.append({\n",
    "            'Context': context,\n",
    "            'Questions': selected_questions\n",
    "        })\n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "# Example usage with DataFrame\n",
    "sample_df = df1.sample(n=500, random_state=42)\n",
    "\n",
    "# questions_list = generate_questions(sample_df)\n",
    "# for record in questions_list:\n",
    "#     print(f\"Context: {record['Context']}\")\n",
    "#     for i, question in enumerate(record['Questions'], 1):\n",
    "#         print(f\"Question {i}: {question}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adfed21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list = generate_questions(sample_df)\n",
    "# for record in questions_list:\n",
    "#     print(f\"Context: {record['Context']}\")\n",
    "#     for i, question in enumerate(record['Questions'], 1):\n",
    "#         print(f\"Question {i}: {question}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ba7c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def generate_questions(sample_df, num_questions=2):\n",
    "    all_questions = []\n",
    "\n",
    "    for _, row in sample_df.iterrows():\n",
    "        context = row['Context']\n",
    "        response = row['Response']\n",
    "        \n",
    "        # Prepare the prompt\n",
    "        prompt = f\"\"\"\n",
    "        You are emulating a person experiencing mental health challenges.\n",
    "        Formulate {num_questions*2} insightful questions based on the following mental health conversation record. \n",
    "        Use the context provided to generate relevant questions, but avoid directly copying words from the response.\n",
    "\n",
    "        Record:\n",
    "        Context: {context}\n",
    "        Response: {response}\n",
    "\n",
    "        Provide the output in the format:\n",
    "        \"Question 1: Question text\"\n",
    "        \"Question 2: Question text\"\n",
    "        ...\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate the questions\n",
    "        result = pipe(prompt, **generation_args)[0][\"generated_text\"]\n",
    "\n",
    "        # Extract questions\n",
    "        questions = []\n",
    "        for line in result.split('\\n'):\n",
    "            if 'Question' in line:\n",
    "                parts = line.split(\":\", 1)\n",
    "                if len(parts) > 1:\n",
    "                    question_text = parts[1].strip()\n",
    "                    if question_text:\n",
    "                        questions.append(question_text)\n",
    "        \n",
    "        # Score and select top num_questions questions\n",
    "        if len(questions) > num_questions:\n",
    "            scores = score_questions(questions, context)\n",
    "            sorted_questions = [q for _, q in sorted(zip(scores, questions), reverse=True)]\n",
    "            selected_questions = sorted_questions[:num_questions]\n",
    "        else:\n",
    "            selected_questions = list(dict.fromkeys(questions))  # Remove duplicates if less than num_questions\n",
    "        \n",
    "        # Add the questions to the list with their corresponding context\n",
    "        all_questions.append({\n",
    "            'Context': context,\n",
    "            'Questions': selected_questions\n",
    "        })\n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "# Example usage with DataFrame\n",
    "sample_df = df1.sample(n=500, random_state=42)\n",
    "\n",
    "# questions_list = generate_questions(sample_df)\n",
    "# for record in questions_list:\n",
    "#     print(f\"Context: {record['Context']}\")\n",
    "#     for i, question in enumerate(record['Questions'], 1):\n",
    "#         print(f\"Question {i}: {question}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa3e8c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "questions_list = generate_questions(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8976c8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1: I've hit my head on walls and floors ever since I was young. I sometimes still do it but I don't exactly know why,    I have anxiety and I had a rough childhood but now I'll start to hit my head and sometimes not realize it but I don't know how to stop or even why I'm doing it.    How can I help myself to change my behavior?\n",
      "\n",
      "Context 2: Over a year ago I had a female friend. She turned out to be kind of crazy so I decided to stop talking to her. When she would call me I wouldn't answer the phone. This made my girlfriend really suspicious. She would ask me why I wouldn't ever answer that phone number. I told my girlfriend that I don't want to be friends with that other woman, but I don't think she believes me. How can I get my girlfriend to understand?\n",
      "\n",
      "Context 3: My long-distance girlfriend is in a sorority, and it's changing her. I feel like I'm becoming less important to her and it hurts. She just wants me to support the sorority, but it's so hard. I try every day to show her she's the most important thing to me, but she can't even stay relatively sober at a fraternity party for me so that I won't worry about her doing anything regretful. We love each other, but we're in a rough patch.\n",
      "  Question 1: How do you both feel about seeking external support, such as from a therapist, and what steps would you be willing to take to consider this option together as a way to strengthen your emotional connection and resolve current issues?\"\n",
      "  Question 2: Have you previously used any form of communication or mediation methods to discuss and resolve challenges in your relationship, and if not, what are some approaches you are open to exploring?\"\n",
      "\n",
      "Context 4: Cheating is something unacceptable for me but because we have two daughters I decided not to break up the family. However, now I am struggling to forget and forgive what happened. I feel like I cannot trust him. Without trust, I cannot stay in this relationship. On the other hand, I do not want my children to get hurt. I'm not sure how to move forward?\n",
      "  Question 1: What steps can you take to ensure that your own emotional journey and healing process are also in the best interest of your children, especially in terms of setting a positive example for how to handle relationship challenges?\"\n",
      "  Question 2: How can setting personal boundaries and practicing self-care contribute to your ability to effectively navigate the complex emotions and decisions involved in moving forward with your relationship and your family's well-being?\"\n",
      "\n",
      "Context 5: I have twin toddlers. I experienced a death of loved one prior to giving birth. I had a horrible break up with the father. People told him he was using me for money. My ex-boyfriend had extreme meltdowns every day for three years. I’m always alone with no friends.\n",
      "  Question 1: In what ways have your past experiences shaped your journey towards self-discovery and growth, and how can we acknowledge and integrate this understanding into your healing process?\n",
      "  Question 2: What are some moments or activities that bring you a sense of peace or joy, and how can we incorporate these into your daily routine to reinforce your resilience?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the first few records to inspect the output\n",
    "for i, record in enumerate(questions_list[:5]):  # Adjust the number as needed\n",
    "    print(f\"Context {i + 1}: {record['Context']}\")\n",
    "    for j, question in enumerate(record['Questions'], 1):\n",
    "        print(f\"  Question {j}: {question}\")\n",
    "    print()  # For spacing between different records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73754e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# Assuming questions_list is your original list\n",
    "questions_list_copy = copy.deepcopy(questions_list)\n",
    "\n",
    "# Now you can apply the ID-assignment function to the copied list\n",
    "# questions_list_with_ids = add_ids_to_questions_list(questions_list_copy)\n",
    "\n",
    "# The original questions_list remains unchanged, and you can inspect questions_list_with_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a21271ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of generated questions: 860\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of questions generated\n",
    "total_questions = sum(len(record['Questions']) for record in questions_list)\n",
    "print(f\"Total number of generated questions: {total_questions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3beecb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 82b18f1d35\n",
      "Context: I've hit my head on walls and floors ever since I was young. I sometimes still do it but I don't exactly know why,    I have anxiety and I had a rough childhood but now I'll start to hit my head and sometimes not realize it but I don't know how to stop or even why I'm doing it.    How can I help myself to change my behavior?\n",
      "\n",
      "ID: b9ea4fc5fa\n",
      "Context: Over a year ago I had a female friend. She turned out to be kind of crazy so I decided to stop talking to her. When she would call me I wouldn't answer the phone. This made my girlfriend really suspicious. She would ask me why I wouldn't ever answer that phone number. I told my girlfriend that I don't want to be friends with that other woman, but I don't think she believes me. How can I get my girlfriend to understand?\n",
      "\n",
      "ID: f307b325d9\n",
      "Context: My long-distance girlfriend is in a sorority, and it's changing her. I feel like I'm becoming less important to her and it hurts. She just wants me to support the sorority, but it's so hard. I try every day to show her she's the most important thing to me, but she can't even stay relatively sober at a fraternity party for me so that I won't worry about her doing anything regretful. We love each other, but we're in a rough patch.\n",
      "  QuestionID: f307b325d9, Question: How do you both feel about seeking external support, such as from a therapist, and what steps would you be willing to take to consider this option together as a way to strengthen your emotional connection and resolve current issues?\"\n",
      "  QuestionID: f307b325d9, Question: Have you previously used any form of communication or mediation methods to discuss and resolve challenges in your relationship, and if not, what are some approaches you are open to exploring?\"\n",
      "\n",
      "ID: 842e439c52\n",
      "Context: Cheating is something unacceptable for me but because we have two daughters I decided not to break up the family. However, now I am struggling to forget and forgive what happened. I feel like I cannot trust him. Without trust, I cannot stay in this relationship. On the other hand, I do not want my children to get hurt. I'm not sure how to move forward?\n",
      "  QuestionID: 842e439c52, Question: What steps can you take to ensure that your own emotional journey and healing process are also in the best interest of your children, especially in terms of setting a positive example for how to handle relationship challenges?\"\n",
      "  QuestionID: 842e439c52, Question: How can setting personal boundaries and practicing self-care contribute to your ability to effectively navigate the complex emotions and decisions involved in moving forward with your relationship and your family's well-being?\"\n",
      "\n",
      "ID: af8cba43be\n",
      "Context: I have twin toddlers. I experienced a death of loved one prior to giving birth. I had a horrible break up with the father. People told him he was using me for money. My ex-boyfriend had extreme meltdowns every day for three years. I’m always alone with no friends.\n",
      "  QuestionID: af8cba43be, Question: In what ways have your past experiences shaped your journey towards self-discovery and growth, and how can we acknowledge and integrate this understanding into your healing process?\n",
      "  QuestionID: af8cba43be, Question: What are some moments or activities that bring you a sense of peace or joy, and how can we incorporate these into your daily routine to reinforce your resilience?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "def add_ids_to_questions_list(questions_list_copy):\n",
    "    # Initialize a new list to store results with IDs\n",
    "    questions_with_ids = []\n",
    "\n",
    "    # Iterate through the questions list and assign unique IDs\n",
    "    for record in questions_list_copy:\n",
    "        context = record['Context']\n",
    "        questions = record['Questions']\n",
    "        \n",
    "        # Generate a unique ID for this context and associated questions\n",
    "        unique_id = uuid.uuid4().hex[:10]  # Generate a shorter unique ID\n",
    "        \n",
    "        # Add ID to each record and the questions\n",
    "        questions_with_ids.append({\n",
    "            'ID': unique_id,\n",
    "            'Context': context,\n",
    "            'Questions': [{'ID': unique_id, 'Question': question} for question in questions]\n",
    "        })\n",
    "\n",
    "    return questions_with_ids\n",
    "\n",
    "# Apply the ID assignment function\n",
    "questions_list_with_ids = add_ids_to_questions_list(questions_list_copy)\n",
    "\n",
    "# Example output inspection\n",
    "for record in questions_list_with_ids[:5]:  # Adjust the number to view more records\n",
    "    print(f\"ID: {record['ID']}\")\n",
    "    print(f\"Context: {record['Context']}\")\n",
    "    for question in record['Questions']:\n",
    "        print(f\"  QuestionID: {question['ID']}, Question: {question['Question']}\")\n",
    "    print()  # For spacing between records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b9cb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Flatten the questions_list_with_ids to create the DataFrame\n",
    "def flatten_questions(questions_list_with_ids):\n",
    "    # Initialize lists to hold data for the DataFrame\n",
    "    question_texts = []\n",
    "    document_ids = []\n",
    "    \n",
    "    for record in questions_list_with_ids:\n",
    "        unique_id = record['ID']\n",
    "        for question in record['Questions']:\n",
    "            question_texts.append(question['Question'])\n",
    "            document_ids.append(unique_id)\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    df2 = pd.DataFrame({\n",
    "        'questions': question_texts,\n",
    "        'documents': document_ids\n",
    "    })\n",
    "    \n",
    "    return df2\n",
    "\n",
    "# Apply the flattening function\n",
    "questions_df = flatten_questions(questions_list_with_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d08fbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(860, 2)\n"
     ]
    }
   ],
   "source": [
    "print(questions_df.shape)  # Should be (860, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59a0a52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do you both feel about seeking external su...</td>\n",
       "      <td>f307b325d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Have you previously used any form of communica...</td>\n",
       "      <td>f307b325d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What steps can you take to ensure that your ow...</td>\n",
       "      <td>842e439c52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can setting personal boundaries and practi...</td>\n",
       "      <td>842e439c52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In what ways have your past experiences shaped...</td>\n",
       "      <td>af8cba43be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are some moments or activities that bring...</td>\n",
       "      <td>af8cba43be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Looking forward, what qualities do you hope to...</td>\n",
       "      <td>8c303a7fdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Reflecting on your own feelings during the bre...</td>\n",
       "      <td>8c303a7fdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Considering the influence of cognitive biases,...</td>\n",
       "      <td>b1023f460a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Reflecting on the role of emotional intelligen...</td>\n",
       "      <td>b1023f460a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions   documents\n",
       "0  How do you both feel about seeking external su...  f307b325d9\n",
       "1  Have you previously used any form of communica...  f307b325d9\n",
       "2  What steps can you take to ensure that your ow...  842e439c52\n",
       "3  How can setting personal boundaries and practi...  842e439c52\n",
       "4  In what ways have your past experiences shaped...  af8cba43be\n",
       "5  What are some moments or activities that bring...  af8cba43be\n",
       "6  Looking forward, what qualities do you hope to...  8c303a7fdc\n",
       "7  Reflecting on your own feelings during the bre...  8c303a7fdc\n",
       "8  Considering the influence of cognitive biases,...  b1023f460a\n",
       "9  Reflecting on the role of emotional intelligen...  b1023f460a"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70ea7201",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save the DataFrame to a CSV file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mquestions_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mground_truth_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/pandas/core/generic.py:3961\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3950\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3952\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3953\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3954\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3958\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3959\u001b[0m )\n\u001b[0;32m-> 3961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3964\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3966\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/pandas/io/formats/csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/pandas/io/formats/csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/pandas/io/formats/csvs.py:324\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[1;32m    323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[0;32m--> 324\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mwriters.pyx:73\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "questions_df.to_csv('ground_truth_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad2929c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "overlay         100G   43G   58G  43% /\r\n",
      "tmpfs            64M     0   64M   0% /dev\r\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/fs/cgroup\r\n",
      "/dev/nvme0n1p1  100G   43G   58G  43% /run\r\n",
      "tmpfs            14G  4.0K   14G   1% /dev/shm\r\n",
      "/dev/nvme2n1    2.0G  1.9G     0 100% /home/jovyan\r\n",
      "tmpfs            14G  120K   14G   1% /home/jovyan/.saturn\r\n",
      "tmpfs            14G   12K   14G   1% /run/secrets/kubernetes.io/serviceaccount\r\n",
      "tmpfs           7.7G   12K  7.7G   1% /proc/driver/nvidia\r\n",
      "tmpfs           7.7G   19M  7.7G   1% /run/nvidia-persistenced/socket\r\n",
      "tmpfs           7.7G     0  7.7G   0% /proc/acpi\r\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/firmware\r\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d191cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the large incomplete Hugging Face cache file to /run/cache/\n",
    "!mv /home/jovyan/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/blobs/fc534bed68dc12e48d1f28d144bfb2239bd1ef4f5d5892d68e9d1f85731b8c12.incomplete /run/cache/\n",
    "\n",
    "# Move the entire Hugging Face cache directory for the specific model to /run/cache/\n",
    "!mv /home/jovyan/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct /run/cache/\n",
    "\n",
    "# Move the pip cache directory to /run/cache/\n",
    "!mv /home/jovyan/.cache/pip /run/cache/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69217eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "overlay         100G   45G   56G  45% /\r\n",
      "tmpfs            64M     0   64M   0% /dev\r\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/fs/cgroup\r\n",
      "/dev/nvme0n1p1  100G   45G   56G  45% /run\r\n",
      "tmpfs            14G  4.0K   14G   1% /dev/shm\r\n",
      "/dev/nvme2n1    2.0G  9.9M  1.9G   1% /home/jovyan\r\n",
      "tmpfs            14G  120K   14G   1% /home/jovyan/.saturn\r\n",
      "tmpfs            14G   12K   14G   1% /run/secrets/kubernetes.io/serviceaccount\r\n",
      "tmpfs           7.7G   12K  7.7G   1% /proc/driver/nvidia\r\n",
      "tmpfs           7.7G   20M  7.7G   1% /run/nvidia-persistenced/socket\r\n",
      "tmpfs           7.7G     0  7.7G   0% /proc/acpi\r\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/firmware\r\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43d2bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "questions_df.to_pickle('questions_documents.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe9632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
